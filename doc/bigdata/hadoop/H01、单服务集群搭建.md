# 一、基础环境

## 1、环境版本

```
环境：centos7
hadoop版本：2.7.2
jdk版本：1.8
```

## 2、Hadoop目录结构

- bin目录：存放对Hadoop的HDFS,YARN服务进行操作的脚本
- etc目录：Hadoop的相关配置文件目录
- lib目录：存放Hadoop的本地库，提供数据压缩解压缩能力
- sbin目录：存放启动或停止Hadoop相关服务的脚本
- share目录：存放Hadoop的依赖jar包、文档、和相关案例

## 3、配置加载

```
vim /etc/profile
# 添加环境
export JAVA_HOME=/opt/jdk1.8
export PATH=$PATH:$JAVA_HOME/bin
export HADOOP_HOME=/opt/hadoop2.7
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# 退出刷新配置
source /etc/profile
```

# 二、伪集群配置

以下配置文件所在路径：/opt/hadoop2.7/etc/hadoop，这里是Linux环境，脚本配置sh格式。

## 1、配置hadoop-env

```
root# vim hadoop-env.sh
# 修改前
export JAVA_HOME=
# 修改后
export JAVA_HOME=/opt/jdk1.8
```

## 2、配置core-site

文件结构概览

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
</configuration>
```

NameNode的地址

```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://127.0.0.1:9000</value>
</property>
```

数据存放目录：Hadoop运行时产生文件的存储目录。

```xml
<property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/hadoop2.7/data/tmp</value>
</property>
```

## 3、配置hdfs-site

文件结构和上述一样，配置hdfs副本个数，这里伪环境，配置1个即可。

```xml
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
```

## 4、配置yarn-env

```
export JAVA_HOME=/opt/jdk1.8
```

## 5、配置yarn-site

指定YARN的ResourceManager的地址

```xml
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>192.168.72.132</value>
</property>
```

指定map产生的中间结果传递给reduce采用的机制是shuffle

```xml
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
```

## 6、配置mapred-env

```
export JAVA_HOME=/opt/jdk1.8
```

## 7、配置mapred-site

将mapred-site.xml.template重新命名为mapred-site.xml。

指定MapReduce程序资源调在度集群上运行。如果不指定为yarn，那么MapReduce程序就只会在本地运行而非在整个集群中运行。

```xml
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
```

# 三、环境启动测试

## 1、测试文件系统

Hdfs相关

**格式化NameNode**

第一次启动时执行该操作。

```
[hadoop2.7]# bin/hdfs namenode -format
```

格式化NameNode，会产生新的clusterID,导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要停止相关进程，删除data数据和log日志，然后再格式化NameNode。clusterID在如下目录中的VERSION文件里，可自行查看对比。

```
/opt/hadoop2.7/data/tmp/dfs/name/current
/opt/hadoop2.7/data/tmp/dfs/data/current
```

**启动NameNode**

```
[hadoop2.7]# sbin/hadoop-daemon.sh start namenode
```

**启动DataNode**

```
[hadoop2.7]# sbin/hadoop-daemon.sh start datanode
```

**jps查看状态**

```
[root@localhost hadoop2.7]# jps
2450 Jps
2276 NameNode
2379 DataNode
```

**Web界面查看**

需要Linux关闭防火墙和相关安全增强控制（这里很重要）。

```
IP地址:50070
```

![](https://images.gitee.com/uploads/images/2022/0213/130543_1a126015_5064118.jpeg "02-1.jpg")

Yarn相关

启动ResourceManager


```
[hadoop2.7]# sbin/yarn-daemon.sh start resourcemanager
```

启动NodeManager

```
[hadoop2.7]# sbin/yarn-daemon.sh start nodemanager
```

Web界面查看

```
IP地址:8088/cluster
```

![](https://images.gitee.com/uploads/images/2022/0213/130557_4055220a_5064118.jpeg "02-2.jpg")

MapReduce相关

**文件操作测试**

创建一个测试文件目录

```
[root@localhost inputfile]# pwd
/opt/inputfile
[root@localhost inputfile]# echo "hello word hadoop" > word.txt
```

HDFS文件系统上创建文件夹

```
[hadoop2.7] bin/hdfs dfs -mkdir -p /opt/upfile/input
```

上传文件

```
[hadoop2.7]# bin/hdfs dfs -put /opt/inputfile/word.txt /opt/upfile/input
```

查看文件

```
[hadoop2.7]# bin/hdfs dfs -ls /opt/upfile/input
```

## 2、Web端查看文件

![](https://images.gitee.com/uploads/images/2022/0213/130611_327c8c5a_5064118.jpeg "02-3.jpg")

执行文件分析

```
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /opt/upfile/input /opt/upfile/output
```

查看分析结果

```
bin/hdfs dfs -cat /opt/upfile/output/*
```

结果：每个单词各自出现一次。

删除分析结果

```
bin/hdfs dfs -rm -r /opt/upfile/output
```

# 四、历史服务器

MapReduce的JobHistoryServer，这是一个独立的服务，可通过 web UI 展示历史作业日志。

## 1、修改mapred-site

```xml
<!-- 服务器端地址 -->
<property>
<name>mapreduce.jobhistory.address</name>
<value>192.168.72.132:10020</value>
</property>

<!-- 服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>192.168.72.132:19888</value>
</property>
```

## 2、启动服务

```
[hadoop2.7]# sbin/mr-jobhistory-daemon.sh start historyserver
```

## 3、Web端查看

```
IP地址:19888
```

![](https://images.gitee.com/uploads/images/2022/0213/130628_3d47a810_5064118.jpeg "02-4.jpg")

## 4、配置日志的聚集

日志聚集概念：应用服务运行完成以后，将运行日志信息上传到HDFS系统上。方便的查看到程序运行详情，方便开发调试。

开启日志聚集功能之后，需要重新启动NodeManager 、ResourceManager和HistoryManager。

**关闭上述服务**

```
[hadoop2.7]# sbin/yarn-daemon.sh stop resourcemanager
[hadoop2.7]# sbin/yarn-daemon.sh stop nodemanager
[hadoop2.7]# sbin/mr-jobhistory-daemon.sh stop historyserver
```

**修改yarn-site**

```xml
<!-- 日志聚集功开启 -->
<property>
<name>yarn.log-aggregation-enable</name>
<value>true</value>
</property>

<!-- 日志保留时间7天 -->
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>604800</value>
</property>
```

修改完之后再次启动上述服务器。再次执行文件分析任务。

**查看Web端**

![](https://images.gitee.com/uploads/images/2022/0213/130641_b5843447_5064118.jpeg "02-5.jpg")

![](https://images.gitee.com/uploads/images/2022/0213/130651_161e37e4_5064118.jpeg "02-6.jpg")

**源码参考：** https://gitee.com/cicadasmile/big-data-parent/tree/master/series01-hadoop-parent