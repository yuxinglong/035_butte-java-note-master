# 一、基础环境配置

## 1、三台服务

准备三台Centos7服务,基础环境从伪分布式环境克隆过来。

```
133 hop01，134 hop02，136 hop03
```

## 2、设置主机名

```
## 设置名称
hostnamectl set-hostname hop01
## 重启
reboot -f
```

## 3、主机名通信

```
vim /etc/hosts
# 添加服务节点
192.168.37.133 hop01
192.168.37.134 hop02
192.168.37.136 hop03
```

## 4、SSH免密登录

配置三台服务SSH免密登录。

```
[root@hop01 ~]# ssh-keygen -t rsa
...一路回车结束
[root@hop01 ~]# cd .ssh
...权限分配到指定集群服务
[root@hop01 .ssh]# ssh-copy-id hop01
[root@hop01 .ssh]# ssh-copy-id hop02
[root@hop01 .ssh]# ssh-copy-id hop03
...在hop01免密登录到hop02
[root@hop01 ~]# ssh hop02
```

这里针对hop01服务，在hop02和hop03服务都要执行该操作。

## 5、同步时间

ntp组件安装

```
# 安装
yum install ntpdate ntp -y
# 查看
rpm -qa|grep ntp
```

基础管理命令

```
# 查看状态
service ntpd status
# 启动
service ntpd start
# 开机启动
chkconfig ntpd on
```

修改时间服务hop01

```
# 修改ntp配置
vim /etc/ntp.conf
# 添加内容
restrict 192.168.0.0 mask 255.255.255.0 nomodify notrap
server 127.0.0.1
fudge 127.0.0.1 stratum 10
```

修改hop02\hop03时间机制，从hop01同步时间，并注销网络获取时间的机制。
```
server 192.168.37.133
# server 0.centos.pool.ntp.org iburst
# server 1.centos.pool.ntp.org iburst
# server 2.centos.pool.ntp.org iburst
# server 3.centos.pool.ntp.org iburst
```

编写定时任务

```
[root@hop02 ~]# crontab -e
*/10 * * * * /usr/sbin/ntpdate hop01
```

修改hop02和hop03服务时间

```
# 指定时间
date -s "2018-05-20 13:14:55"
# 查看时间
date
```

这样时间会基于hop01服务的时间不断的更正或同步。

## 6、环境清理

从伪分布式环境虚拟机克隆三台Centos7服务,删除原来hadoop环境配置的data和log文件夹。

```
[root@hop02 hadoop2.7]# rm -rf data/ logs/
```

# 二、集群环境搭建

## 1、集群配置概览

|服务列表 | HDFS文件 | YARN调度 | 单服务 |
|---|---|---|---|
|hop01 | DataNode | NodeManager | NameNode |
|hop02 | DataNode | NodeManager | ResourceManager |
|hop03 | DataNode | NodeManager | SecondaryNameNode |

## 2、修改配置

**vim core-site.xml**

```
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hop01:9000</value>
</property>
```

这里三台服务都需要分别指定当前主机名称。

**vim hdfs-site.xml**

```
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>

<property>
      <name>dfs.namenode.secondary.http-address</name>
      <value>hop03:50090</value>
</property>
```

这里修改副本数为3，并指定SecondaryNameNode服务，三台服务同样修改指定SecondaryNameNode在hop03服务上。


**vim yarn-site.xml**

```
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hop02</value>
</property>
```

指定ResourceManager服务在hop02上。

**vim mapred-site.xml**

```
<!-- 服务器端地址 -->
<property>
<name>mapreduce.jobhistory.address</name>
<value>hop01:10020</value>
</property>

<!-- 服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hop01:19888</value>
</property>
```

指定相关web端查看地址在服务hop01上。

## 3、集群服务配置

路径：**/opt/hadoop2.7/etc/hadoop**

文件：**vim slaves**

```
hop01
hop02
hop03
```

这里配置三台服务的集群列表。同步修改其他服务相同配置。

## 4、格式化NameNode

注意这里NameNode配置在hop01服务上。

```
[root@hop01 hadoop2.7]# bin/hdfs namenode -format
```

## 5、启动HDFS

```
[root@hop01 hadoop2.7]# sbin/start-dfs.sh
Starting namenodes on [hop01]
hop01: starting namenode
hop03: starting datanode
hop02: starting datanode
hop01: starting datanode
Starting secondary namenodes [hop03]
hop03: starting secondarynamenode
```

注意看这里的打印信息，和配置完全吻合。namenodes在hop01上启动，secondary-namenodes在hop03上启动，可以通过JPS命令到各个服务查看验证。


## 6、启动YARN

注意Yarn配置在hop02服务上，所以在hop02服务执行启动命令。

```
[root@hop02 hadoop2.7]# sbin/start-yarn.sh
starting yarn daemons
starting resourcemanager
hop03: starting nodemanager
hop01: starting nodemanager
hop02: starting nodemanager,
```

注意这里的启动打印日志，至此集群规划的服务都启动完毕。

```
[root@hop01 hadoop2.7]# jps
4306 NodeManager
4043 DataNode
3949 NameNode
[root@hop02 hadoop2.7]# jps
3733 ResourceManager
3829 NodeManager
3613 DataNode
[root@hop03 hadoop2.7]# jps
3748 DataNode
3928 NodeManager
3803 SecondaryNameNode
```

查看各个服务下的集群进程，与规划配置一致。

## 7、Web端界面

```
NameNode：http://hop01:50070
SecondaryNameNode：http://hop03:50090
```

**源码参考：** https://gitee.com/cicadasmile/big-data-parent/tree/master/series01-hadoop-parent
